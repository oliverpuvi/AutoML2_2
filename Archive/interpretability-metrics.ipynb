{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for three interpretability techniques: LIME, ANCHOR, CIU\n",
    "\n",
    "Metrics tested are identity, separability, fidelity, and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "\n",
    "import metrics_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the datasets folder\n",
    "datasets_folder = \"../datasets\"\n",
    "\n",
    "# Initialize empty lists to store dataframes for each file\n",
    "folder_names = []\n",
    "attribute_names_list = []\n",
    "categorical_indicator_list = []\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Loop through each folder in the datasets folder\n",
    "for folder_name in os.listdir(datasets_folder):\n",
    "    folder_path = os.path.join(datasets_folder, folder_name)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Construct file paths for each CSV file in the folder\n",
    "        attribute_names_path = os.path.join(folder_path, \"attribute_names.csv\")\n",
    "        categorical_indicator_path = os.path.join(folder_path, \"categorical_indicator.csv\")\n",
    "        X_path = os.path.join(folder_path, \"X.csv\")\n",
    "        y_path = os.path.join(folder_path, \"y.csv\")\n",
    "        \n",
    "        # Read each CSV file into a pandas dataframe\n",
    "        attribute_names_df = pd.read_csv(attribute_names_path)\n",
    "        categorical_indicator_df = pd.read_csv(categorical_indicator_path)\n",
    "        X_df = pd.read_csv(X_path)\n",
    "        y_df = pd.read_csv(y_path)\n",
    "        \n",
    "        # Append dataframes to the lists\n",
    "        attribute_names_list.append(attribute_names_df)\n",
    "        categorical_indicator_list.append(categorical_indicator_df)\n",
    "        X_list.append(X_df)\n",
    "        y_list.append(y_df)\n",
    "\n",
    "        # Save folder name to list\n",
    "        folder_names.append(folder_name)\n",
    "\n",
    "X = [df.head(50) for df in X_list]\n",
    "y = [df.head(50) for df in y_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def convert_to_numeric_and_impute(X_list, y_list):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    def process_dataframe(df):\n",
    "        for column in df.columns:\n",
    "            if isinstance(df[column].iloc[0], csr_matrix):\n",
    "                df[column] = df[column].apply(lambda x: x.toarray()[0,0] if x.shape[1] == 1 else x.toarray())\n",
    "\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "            if df[column].dtype == 'object':\n",
    "                # Fill NaN with a placeholder and then label encode\n",
    "                df[column] = df[column].fillna('Missing')\n",
    "                df[column] = label_encoder.fit_transform(df[column])\n",
    "            else:\n",
    "                if df[column].notna().any():\n",
    "                    df[column] = imputer.fit_transform(df[[column]]).ravel()\n",
    "                else:\n",
    "                    df[column] = df[column].fillna(0)\n",
    "\n",
    "        return df\n",
    "\n",
    "    X_list = [process_dataframe(df) for df in X_list]\n",
    "    y_list = [process_dataframe(df) for df in y_list]\n",
    "\n",
    "    return X_list, y_list\n",
    "\n",
    "X, y = convert_to_numeric_and_impute(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One dataset here, gen five later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1050 - Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[0], y[0], test_size=0.2, random_state=555)\n",
    "\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=50, n_jobs=5)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = accuracy_score(y_test, rf.predict(X_test))\n",
    "print(f\"Dataset {folder_names[i]} - Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29387831687927246\n",
      "(10.0, 9, 10)\n",
      "(14, 10, 100, 14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = np.unique(y_train).tolist()\n",
    "attribute_names = X_train.columns.tolist()\n",
    "\n",
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    class_names,\n",
    "    attribute_names,\n",
    "    X_train.values)\n",
    "\n",
    "def exp_fn_blk(xtest):\n",
    "    exp1 = []\n",
    "    for i in tqdm.tqdm(range(len(xtest))):\n",
    "        start_clock = time.time()\n",
    "        exp = explainer.explain_instance(X_test.values[i], rf.predict, threshold=0.95)\n",
    "        end_clock = time.time()\n",
    "        calc_time = end_clock - start_clock\n",
    "        exp_list = [0]*len(X_train.columns)\n",
    "        for j in exp.features():\n",
    "            exp_list[j] = 1\n",
    "        exp1.append(exp_list)\n",
    "    return np.array(exp1), calc_time\n",
    "    \n",
    "exp1 = exp_fn_blk(X_test)\n",
    "exp2 = exp_fn_blk(X_test)\n",
    "\n",
    "print((exp1[1] + exp2[1]) / 2)\n",
    "print(metrics_rules.calc_identity_rules(exp1[0], exp2[0]))\n",
    "print(metrics_rules.calc_separability_rules(exp1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9819878557758586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "prec = 0\n",
    "for i in tqdm.tqdm(range(len(X_test))):\n",
    "    exp = explainer.explain_instance(X_test.values[i], rf.predict, threshold=0.95)\n",
    "    prec += exp.precision()\n",
    "print(prec/len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANCHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1046 - Accuracy: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1049 - Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.77s/it]\n",
      "100%|██████████| 10/10 [00:21<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1050 - Accuracy: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|██████████| 10/10 [00:16<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1053 - Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.77it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1063 - Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.96it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Store scores\n",
    "identity_anchor_scores = []\n",
    "separability_anchor_scores = []\n",
    "speed_anchor_seconds = []\n",
    "precision_scores = []\n",
    "\n",
    "# for i in range(len(X)):\n",
    "for i in range(5):\n",
    "    \n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[i], y[i], test_size=0.2, random_state=555)\n",
    "\n",
    "    rf = sklearn.ensemble.RandomForestClassifier(n_estimators=50, n_jobs=5)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, rf.predict(X_test))\n",
    "    print(f\"Dataset {folder_names[i]} - Accuracy: {accuracy}\")\n",
    "\n",
    "    explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    np.unique(y_train).tolist(),\n",
    "    X_train.columns.tolist(),\n",
    "    X_train.values)\n",
    "\n",
    "    def exp_fn_blk(xtest):\n",
    "        exp1 = []\n",
    "        prec = 0\n",
    "        for i in tqdm.tqdm(range(len(xtest))):\n",
    "            start_clock = time.time()\n",
    "            exp = explainer.explain_instance(X_test.values[i], rf.predict, threshold=0.95)\n",
    "            end_clock = time.time()\n",
    "            prec += exp.precision()\n",
    "            calc_time = end_clock - start_clock\n",
    "            exp_list = [0]*len(X_train.columns)\n",
    "            for j in exp.features():\n",
    "                exp_list[j] = 1\n",
    "            exp1.append(exp_list)\n",
    "        return np.array(exp1), calc_time, prec\n",
    "\n",
    "    exp1 = exp_fn_blk(X_test)\n",
    "    exp2 = exp_fn_blk(X_test)\n",
    "\n",
    "    precision_scores.append(exp1[2]/len(X_test))\n",
    "    speed_anchor_seconds.append((exp1[1] + exp2[1]) / 2)\n",
    "    identity_anchor_scores.append(metrics_rules.calc_identity_rules(exp1[0], exp2[0]))\n",
    "    separability_anchor_scores.append(metrics_rules.calc_separability_rules(exp1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50.0, 5, 10), (50.0, 5, 10), (70.0, 3, 10), (70.0, 3, 10), (0.0, 10, 10)]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_anchor_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 10, 100, 14.0),\n",
       " (22, 10, 100, 22.0),\n",
       " (30, 10, 100, 30.0),\n",
       " (12, 10, 100, 12.0),\n",
       " (90, 10, 100, 90.0)]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separability_anchor_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3924214839935303,\n",
       " 1.7786080837249756,\n",
       " 2.4819605350494385,\n",
       " 0.44764697551727295,\n",
       " 0.06706643104553223]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed_anchor_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9821836593716078,\n",
       " 0.972625886011248,\n",
       " 0.994059405940594,\n",
       " 0.996009553655405,\n",
       " 1.0]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.concat([\n",
    "    pd.Series(identity_anchor_scores, name='identity_anchor_scores'),\n",
    "    pd.Series(separability_anchor_scores, name='separability_anchor_scores'),\n",
    "    pd.Series(speed_anchor_seconds, name='speed_anchor_seconds'),\n",
    "    pd.Series(precision_scores, name='precision_scores')\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.to_csv('5_records_anchor.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
