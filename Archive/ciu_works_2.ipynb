{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7488f2f",
   "metadata": {},
   "source": [
    "# CIU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5db33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from ciu import determine_ciu\n",
    "import six\n",
    "import sys\n",
    "import os\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from skrules import SkopeRules\n",
    "import openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ciu import determine_ciu\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tqdm\n",
    "import metrics_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3360d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the datasets folder\n",
    "datasets_folder = \"datasets\"\n",
    "\n",
    "# Initialize empty lists to store dataframes for each file\n",
    "folder_names = []\n",
    "attribute_names_list = []\n",
    "categorical_indicator_list = []\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Loop through each folder in the datasets folder\n",
    "for folder_name in os.listdir(datasets_folder):\n",
    "    folder_path = os.path.join(datasets_folder, folder_name)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Construct file paths for each CSV file in the folder\n",
    "        attribute_names_path = os.path.join(folder_path, \"attribute_names.csv\")\n",
    "        categorical_indicator_path = os.path.join(folder_path, \"categorical_indicator.csv\")\n",
    "        X_path = os.path.join(folder_path, \"X.csv\")\n",
    "        y_path = os.path.join(folder_path, \"y.csv\")\n",
    "        \n",
    "        # Read each CSV file into a pandas dataframe\n",
    "        attribute_names_df = pd.read_csv(attribute_names_path)\n",
    "        categorical_indicator_df = pd.read_csv(categorical_indicator_path)\n",
    "        X_df = pd.read_csv(X_path)\n",
    "        y_df = pd.read_csv(y_path)\n",
    "        \n",
    "        # Append dataframes to the lists\n",
    "        attribute_names_list.append(attribute_names_df)\n",
    "        categorical_indicator_list.append(categorical_indicator_df)\n",
    "        X_list.append(X_df)\n",
    "        y_list.append(y_df)\n",
    "\n",
    "        # Save folder name to list\n",
    "        folder_names.append(folder_name)\n",
    "\n",
    "# Subsetting for less expensive runs\n",
    "X_list = [df.head(50) for df in X_list]\n",
    "y_list = [df.head(50) for df in y_list]\n",
    "\n",
    "# For testing the techniques\n",
    "X = X_list[:40]\n",
    "y = y_list[:40]\n",
    "\n",
    "# Names of chosen datasets\n",
    "X_folder_names = folder_names[:40]\n",
    "\n",
    "# For testing later\n",
    "X_list_test = X_list[-10:]\n",
    "y_list_test = y_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def convert_to_numeric_and_impute(X_list, y_list):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    def process_dataframe(df):\n",
    "        for column in df.columns:\n",
    "            if isinstance(df[column].iloc[0], csr_matrix):\n",
    "                df[column] = df[column].apply(lambda x: x.toarray()[0,0] if x.shape[1] == 1 else x.toarray())\n",
    "\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "            if df[column].dtype == 'object':\n",
    "                # Fill NaN with a placeholder and then label encode\n",
    "                df[column] = df[column].fillna('Missing')\n",
    "                df[column] = label_encoder.fit_transform(df[column])\n",
    "            else:\n",
    "                if df[column].notna().any():\n",
    "                    df[column] = imputer.fit_transform(df[[column]]).ravel()\n",
    "                else:\n",
    "                    df[column] = df[column].fillna(0)\n",
    "\n",
    "        return df\n",
    "\n",
    "    X_list = [process_dataframe(df) for df in X_list]\n",
    "    y_list = [process_dataframe(df) for df in y_list]\n",
    "\n",
    "    return X_list, y_list\n",
    "\n",
    "X, y = convert_to_numeric_and_impute(X, y)\n",
    "X_list_test, y_list_test = convert_to_numeric_and_impute(X_list_test, y_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_ciu_as_prediction(ciu_result, threshold=0.5):\n",
    "    # Assuming ciu_result is a list of tuples (feature, importance)\n",
    "    # And that a higher cumulative importance suggests a particular class (e.g., class 1)\n",
    "    cumulative_importance = sum(importance for feature, importance in ciu_result)\n",
    "    return 1 if cumulative_importance > threshold else 0\n",
    "\n",
    "def calculate_fidelity_score(X_test, model, ciu_results):\n",
    "    model_predictions = model.predict(X_test)\n",
    "    ciu_predictions = [interpret_ciu_as_prediction(ciu_result) for ciu_result in ciu_results]\n",
    "    correct_predictions = sum(ciu_pred == model_pred for ciu_pred, model_pred in zip(ciu_predictions, model_predictions))\n",
    "    fidelity_score = correct_predictions / len(X_test)\n",
    "    return fidelity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe84195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_interp = pd.DataFrame(columns=[\"Dataset\", \"Fidelity\", \"Identity\", \"Separability\", \"Speed\"])\n",
    "\n",
    "\n",
    "for i in range(len(X_list)):\n",
    "    print(i)\n",
    "    X, y = X_list[i], y_list[i].squeeze()  # Ensure y is a 1D array\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=555)\n",
    "    feat_list = X_train.columns.tolist()\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    def exp_fn_blk(xtest):\n",
    "        exp1 = []\n",
    "        for i in range(len(xtest)):\n",
    "            exp = determine_ciu(X_test.iloc[i:i+1], model.predict_proba, X_train.to_dict('list'), samples = 100, prediction_index = 1)\n",
    "            exp_list = [[feat_list.index(i), exp.ci[i]] for i in exp.ci]\n",
    "            exp1.append(exp_list)\n",
    "        return np.array(exp1)\n",
    "\n",
    "\n",
    "    start_time = time.time() \n",
    "    exp1 = exp_fn_blk(X_test[:100])\n",
    "    exp2 = exp_fn_blk(X_test[:100])\n",
    "    end_time = time.time()\n",
    "    speed = end_time - start_time \n",
    "    \n",
    "    ciu_fidelity = calculate_fidelity_score(X_test, model, exp1)\n",
    "    \n",
    "    \n",
    "    df_interp = df_interp.append({\n",
    "        \"Dataset\": i,\n",
    "        \"Fidelity\": ciu_fidelity,\n",
    "        \"Identity\": metrics_rules.calc_identity_rules(exp1[0], exp2[0])[0],\n",
    "        \"Separability\": metrics_rules.calc_separability_rules(exp1[0])[0],\n",
    "        \"Speed\": speed\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10710de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding \"ciu_\" prefix to every column name\n",
    "df_interp.columns = ['ciu_' + col for col in df_interp.columns]\n",
    "\n",
    "df_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interp.to_csv('records_ciu.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
