{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for three interpretability techniques: LIME, ANCHOR, CIU\n",
    "\n",
    "Metrics tested are identity, separability, fidelity, and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "\n",
    "import metrics_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the datasets folder\n",
    "datasets_folder = \"../datasets\"\n",
    "\n",
    "# Initialize empty lists to store dataframes for each file\n",
    "folder_names = []\n",
    "attribute_names_list = []\n",
    "categorical_indicator_list = []\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Loop through each folder in the datasets folder\n",
    "for folder_name in os.listdir(datasets_folder):\n",
    "    folder_path = os.path.join(datasets_folder, folder_name)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Construct file paths for each CSV file in the folder\n",
    "        attribute_names_path = os.path.join(folder_path, \"attribute_names.csv\")\n",
    "        categorical_indicator_path = os.path.join(folder_path, \"categorical_indicator.csv\")\n",
    "        X_path = os.path.join(folder_path, \"X.csv\")\n",
    "        y_path = os.path.join(folder_path, \"y.csv\")\n",
    "        \n",
    "        # Read each CSV file into a pandas dataframe\n",
    "        attribute_names_df = pd.read_csv(attribute_names_path)\n",
    "        categorical_indicator_df = pd.read_csv(categorical_indicator_path)\n",
    "        X_df = pd.read_csv(X_path)\n",
    "        y_df = pd.read_csv(y_path)\n",
    "        \n",
    "        # Append dataframes to the lists\n",
    "        attribute_names_list.append(attribute_names_df)\n",
    "        categorical_indicator_list.append(categorical_indicator_df)\n",
    "        X_list.append(X_df)\n",
    "        y_list.append(y_df)\n",
    "\n",
    "        # Save folder name to list\n",
    "        folder_names.append(folder_name)\n",
    "\n",
    "# Subsetting for less expensive runs\n",
    "X_list = [df.head(50) for df in X_list]\n",
    "y_list = [df.head(50) for df in y_list]\n",
    "\n",
    "# For testing the techniques\n",
    "X = X_list[:40]\n",
    "y = y_list[:40]\n",
    "\n",
    "# Names of chosen datasets\n",
    "X_folder_names = folder_names[:40]\n",
    "\n",
    "# For testing later\n",
    "X_list_test = X_list[-10:]\n",
    "y_list_test = y_list[-10:]\n",
    "\n",
    "# Names of testing folder names\n",
    "X_folder_names_test = folder_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def convert_to_numeric_and_impute(X_list, y_list):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    def process_dataframe(df):\n",
    "        for column in df.columns:\n",
    "            if isinstance(df[column].iloc[0], csr_matrix):\n",
    "                df[column] = df[column].apply(lambda x: x.toarray()[0,0] if x.shape[1] == 1 else x.toarray())\n",
    "\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "            if df[column].dtype == 'object':\n",
    "                # Fill NaN with a placeholder and then label encode\n",
    "                df[column] = df[column].fillna('Missing')\n",
    "                df[column] = label_encoder.fit_transform(df[column])\n",
    "            else:\n",
    "                if df[column].notna().any():\n",
    "                    df[column] = imputer.fit_transform(df[[column]]).ravel()\n",
    "                else:\n",
    "                    df[column] = df[column].fillna(0)\n",
    "\n",
    "        return df\n",
    "\n",
    "    X_list = [process_dataframe(df) for df in X_list]\n",
    "    y_list = [process_dataframe(df) for df in y_list]\n",
    "\n",
    "    return X_list, y_list\n",
    "\n",
    "X, y = convert_to_numeric_and_impute(X, y)\n",
    "X_list_test, y_list_test = convert_to_numeric_and_impute(X_list_test, y_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata generation\n",
    "from pymfe.mfe import MFE\n",
    "\n",
    "# Check all available meta-features in the package\n",
    "# print(MFE.valid_metafeatures()) # <- should choose more?????\n",
    "\n",
    "columns = ['attr_to_inst',  'cat_to_num',  'freq_class.mean',  'freq_class.sd',  'inst_to_attr',  'max.mean',  'max.sd',  'min.mean',  'min.sd',  'nr_cor_attr',  'nr_norm',  'sd.mean',  'sd.sd']\n",
    "\n",
    "metadata_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(len(X)):\n",
    "\n",
    "    mfe = MFE(features=[\"attr_to_inst\", \"cat_to_num\", \"freq_class\", \"inst_to_attr\", \"sd\", \"nr_norm\", \"nr_cor_attr\", \"min\", \"max\"])\n",
    "    mfe.fit(np.array(X[i]), np.array(y[i]))\n",
    "    ft = mfe.extract(\n",
    "        sd={\"ddof\": 0},\n",
    "        nr_norm={\"method\": \"all\", \"failure\": \"hard\", \"threshold\": 0.025},\n",
    "        nr_cor_attr={\"threshold\": 0.6},\n",
    "    )\n",
    "\n",
    "    new = pd.DataFrame(np.array(ft[1]).reshape(1, -1), columns=ft[0])\n",
    "    metadata_df = metadata_df.append(new, ignore_index=True)\n",
    "\n",
    "# metadata_df['folder'] = X_folder_names\n",
    "# metadata_df['folder'] = metadata_df['folder'].astype(int)\n",
    "# metadata_df.head()\n",
    "\n",
    "# df_t.to_csv('metadata_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing different techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metafeatures\n",
    "df_meta = pd.read_csv('metadata_merged.csv', index_col=0)\n",
    "df_meta = df_meta.drop(columns= 'best_technique')\n",
    "\n",
    "# Reading in data generated on training data\n",
    "df_lime=pd.read_csv('records_lime.csv', index_col=0).drop(columns = 'lime_Dataset')\n",
    "df_ciu=pd.read_csv('records_ciu.csv', index_col=0).drop(columns = 'ciu_Dataset')\n",
    "df_anchor=pd.read_csv('records_anchor.csv', index_col=0).drop(columns = 'anchor_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_dataset</th>\n",
       "      <th>attr_to_inst</th>\n",
       "      <th>cat_to_num</th>\n",
       "      <th>freq_class.mean</th>\n",
       "      <th>freq_class.sd</th>\n",
       "      <th>inst_to_attr</th>\n",
       "      <th>max.mean</th>\n",
       "      <th>max.sd</th>\n",
       "      <th>min.mean</th>\n",
       "      <th>min.sd</th>\n",
       "      <th>nr_cor_attr</th>\n",
       "      <th>nr_norm</th>\n",
       "      <th>sd.mean</th>\n",
       "      <th>sd.sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ciu_score</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>1.150537</td>\n",
       "      <td>-0.869333</td>\n",
       "      <td>1.195318</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.408634</td>\n",
       "      <td>0.211223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lime_score</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>2.380952</td>\n",
       "      <td>2612.363810</td>\n",
       "      <td>10464.872064</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.421704</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>7.0</td>\n",
       "      <td>716.383714</td>\n",
       "      <td>2875.465961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ciu_score</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>98.125000</td>\n",
       "      <td>5.072906</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>3.630922</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.379573</td>\n",
       "      <td>7.083823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lime_score</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.092229</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>117.528571</td>\n",
       "      <td>229.003710</td>\n",
       "      <td>30.262857</td>\n",
       "      <td>68.736894</td>\n",
       "      <td>0.065546</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.665882</td>\n",
       "      <td>56.092301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ciu_score</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>31.640000</td>\n",
       "      <td>13.351233</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>8.583325</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.264854</td>\n",
       "      <td>2.973742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  best_dataset  attr_to_inst  cat_to_num  freq_class.mean  freq_class.sd  \\\n",
       "0    ciu_score          0.24         0.0         1.000000       0.000000   \n",
       "1   lime_score          0.42         0.0         0.500000       0.480000   \n",
       "2    ciu_score          0.32         0.0         0.100000       0.026833   \n",
       "3   lime_score          0.70         0.0         0.142857       0.092229   \n",
       "4    ciu_score          0.14         0.0         1.000000       0.000000   \n",
       "\n",
       "   inst_to_attr     max.mean        max.sd   min.mean     min.sd  nr_cor_attr  \\\n",
       "0      4.166667     0.595833      1.150537  -0.869333   1.195318     0.151515   \n",
       "1      2.380952  2612.363810  10464.872064   0.764286   0.421704     0.595238   \n",
       "2      3.125000    98.125000      5.072906   0.937500   3.630922     0.125000   \n",
       "3      1.428571   117.528571    229.003710  30.262857  68.736894     0.065546   \n",
       "4      7.142857    31.640000     13.351233   4.571429   8.583325     0.095238   \n",
       "\n",
       "   nr_norm     sd.mean        sd.sd  \n",
       "0      4.0    0.408634     0.211223  \n",
       "1      7.0  716.383714  2875.465961  \n",
       "2      2.0   30.379573     7.083823  \n",
       "3      2.0   24.665882    56.092301  \n",
       "4      0.0    8.264854     2.973742  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define metrics\n",
    "common_columns = ['Fidelity', 'Identity', 'Separability', 'Speed']\n",
    "\n",
    "for col in common_columns:\n",
    "    max_value = max(df_lime['lime_' + col].max(), df_ciu['ciu_' + col].max(), df_anchor['anchor_' + col].max())\n",
    "    df_lime['lime_' + col] /= max_value\n",
    "    df_ciu['ciu_' + col] /= max_value\n",
    "    df_anchor['anchor_' + col] /= max_value\n",
    "\n",
    "merged_df = df_lime.merge(df_ciu, on='folder').merge(df_anchor, on='folder')\n",
    "\n",
    "merged_df['lime_score'] = merged_df['lime_Fidelity'] + merged_df['lime_Identity'] - merged_df['lime_Separability'] - merged_df['lime_Speed']\n",
    "merged_df['ciu_score'] = merged_df['ciu_Fidelity'] + merged_df['ciu_Identity'] - merged_df['ciu_Separability'] - merged_df['ciu_Speed']\n",
    "merged_df['anchor_score'] = merged_df['anchor_Fidelity'] + merged_df['anchor_Identity'] - merged_df['anchor_Separability'] - merged_df['anchor_Speed']\n",
    "\n",
    "merged_df['best_dataset'] = merged_df[['lime_score', 'ciu_score', 'anchor_score']].idxmax(axis=1)\n",
    "\n",
    "selected_datasets = merged_df[['folder', 'best_dataset']]\n",
    "selected_datasets=selected_datasets.merge(df_meta, on='folder')\n",
    "selected_datasets = selected_datasets.drop(columns='folder')\n",
    "\n",
    "selected_datasets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Classification Report for the Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ciu_score       1.00      1.00      1.00        10\n",
      "  lime_score       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the metamodel\n",
    "X = selected_datasets.drop(['best_dataset'], axis=1)\n",
    "y = selected_datasets['best_dataset']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report for the Best Model:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr_to_inst</th>\n",
       "      <th>cat_to_num</th>\n",
       "      <th>freq_class.mean</th>\n",
       "      <th>freq_class.sd</th>\n",
       "      <th>inst_to_attr</th>\n",
       "      <th>max.mean</th>\n",
       "      <th>max.sd</th>\n",
       "      <th>min.mean</th>\n",
       "      <th>min.sd</th>\n",
       "      <th>nr_cor_attr</th>\n",
       "      <th>nr_norm</th>\n",
       "      <th>sd.mean</th>\n",
       "      <th>sd.sd</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461235</td>\n",
       "      <td>0.042153</td>\n",
       "      <td>40496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>51.394163</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>27.111621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.666059</td>\n",
       "      <td>7.054412</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.966667</td>\n",
       "      <td>0.179505</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.222545</td>\n",
       "      <td>4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.076613</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.418699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.968246</td>\n",
       "      <td>1.034553</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>22.444444</td>\n",
       "      <td>30.430654</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>27.828842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.740387</td>\n",
       "      <td>4.278423</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>187.444444</td>\n",
       "      <td>207.204468</td>\n",
       "      <td>82.222222</td>\n",
       "      <td>63.702918</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.986923</td>\n",
       "      <td>36.177679</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>1.713914</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.675886</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.231966</td>\n",
       "      <td>0.401749</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attr_to_inst  cat_to_num  freq_class.mean  freq_class.sd  inst_to_attr  \\\n",
       "0          0.14         0.0              0.1       0.021909      7.142857   \n",
       "1          0.70         0.0              1.0       0.000000      1.428571   \n",
       "2          0.10         0.0              1.0       0.000000     10.000000   \n",
       "3          0.60         0.0              0.5       0.040000      1.666667   \n",
       "4          0.64         0.0              1.0       0.000000      1.562500   \n",
       "5          0.08         0.0              1.0       0.000000     12.500000   \n",
       "6          0.18         0.0              1.0       0.000000      5.555556   \n",
       "7          0.18         0.0              1.0       0.000000      5.555556   \n",
       "8          0.36         0.0              1.0       0.000000      2.777778   \n",
       "9          0.32         0.0              1.0       0.000000      3.125000   \n",
       "\n",
       "     max.mean      max.sd   min.mean     min.sd  nr_cor_attr  nr_norm  \\\n",
       "0    1.000000    0.000000   0.000000   0.000000     0.000000      0.0   \n",
       "1    0.000000    0.000000   0.000000   0.000000     0.000000      0.0   \n",
       "2   39.200000   51.394163  17.600000  27.111621     0.000000      1.0   \n",
       "3    1.000000    0.000000  -0.966667   0.179505     0.020690      0.0   \n",
       "4    0.002553    0.003049  -0.001513   0.002409     0.076613      5.0   \n",
       "5    3.250000    3.418699   0.000000   0.000000     0.000000      0.0   \n",
       "6   22.444444   30.430654  10.333333  27.828842     0.000000      3.0   \n",
       "7    0.000000    0.000000   0.000000   0.000000     0.000000      0.0   \n",
       "8  187.444444  207.204468  82.222222  63.702918     0.372549      4.0   \n",
       "9   11.750000    1.713914   0.937500   1.675886     0.091667      4.0   \n",
       "\n",
       "     sd.mean      sd.sd  folder  \n",
       "0   0.461235   0.042153   40496  \n",
       "1   0.000000   0.000000      42  \n",
       "2   5.666059   7.054412     451  \n",
       "3   0.731250   0.222545    4534  \n",
       "4   0.000671   0.000759    4538  \n",
       "5   0.968246   1.034553     469  \n",
       "6   2.740387   4.278423     470  \n",
       "7   0.000000   0.000000      50  \n",
       "8  22.986923  36.177679      54  \n",
       "9   2.231966   0.401749       6  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata generation for test data\n",
    "columns = ['attr_to_inst',  'cat_to_num',  'freq_class.mean',  'freq_class.sd',  'inst_to_attr',  'max.mean',  'max.sd',  'min.mean',  'min.sd',  'nr_cor_attr',  'nr_norm',  'sd.mean',  'sd.sd']\n",
    "\n",
    "metadata_df_test = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(len(X_list_test)):\n",
    "\n",
    "    mfe = MFE(features=[\"attr_to_inst\", \"cat_to_num\", \"freq_class\", \"inst_to_attr\", \"sd\", \"nr_norm\", \"nr_cor_attr\", \"min\", \"max\"])\n",
    "    mfe.fit(np.array(X_list_test[i]), np.array(y_list_test[i]))\n",
    "    ft = mfe.extract(\n",
    "        sd={\"ddof\": 0},\n",
    "        nr_norm={\"method\": \"all\", \"failure\": \"hard\", \"threshold\": 0.025},\n",
    "        nr_cor_attr={\"threshold\": 0.6},\n",
    "    )\n",
    "\n",
    "    new = pd.DataFrame(np.array(ft[1]).reshape(1, -1), columns=ft[0])\n",
    "    metadata_df_test = metadata_df_test.append(new, ignore_index=True)\n",
    "\n",
    "metadata_df_test['folder'] = X_folder_names_test\n",
    "metadata_df_test['folder'] = metadata_df_test['folder'].astype(int)\n",
    "metadata_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_best_dataset(input_data):\n",
    "\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    input_df = input_df[X.columns]\n",
    "\n",
    "    prediction = best_model.predict(input_df)\n",
    "\n",
    "    return prediction[0][:-6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example on one test dataset and its recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Best Model for your cause, considering your dataset is CIU\n"
     ]
    }
   ],
   "source": [
    "input_data = metadata_df_test.drop(columns='folder').iloc[0].to_dict()\n",
    "input_data_formatted = {k: round(v, 2) for k, v in input_data.items()}\n",
    "\n",
    "predicted_dataset = predict_best_dataset(input_data_formatted)\n",
    "print(\"Predicted Best Model for your cause, considering your dataset is\", predicted_dataset.upper())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
